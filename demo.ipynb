{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone the repo \n",
    "(commented out because it run locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf early_exit\n",
    "# !git clone https://github.com/Ilias-Paralikas/early_exit.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import lirbraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_exit import EarlyExitNetwork,train_model,test_all_exits_accuracy\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\paral/.cache\\torch\\hub\\chenyaofo_pytorch-cifar-models_master\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_vgg19_bn\", pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine model structure\n",
    "you will need see your model layers and determine the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU(inplace=True)\n",
       "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (19): ReLU(inplace=True)\n",
       "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (32): ReLU(inplace=True)\n",
       "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (35): ReLU(inplace=True)\n",
       "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (38): ReLU(inplace=True)\n",
       "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (42): ReLU(inplace=True)\n",
       "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (45): ReLU(inplace=True)\n",
       "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (48): ReLU(inplace=True)\n",
       "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (51): ReLU(inplace=True)\n",
       "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the core network nn.Sequential\n",
    "the way that you do this depends on your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [7,17]\n",
    "device_side_net = deepcopy(pretrained_model.features[:splits[0]])\n",
    "server_side_net = deepcopy(pretrained_model.features[splits[0]:splits[1]])\n",
    "cloud_side_net = nn.Sequential(\n",
    "    deepcopy(pretrained_model.features[splits[1]:]),\n",
    "    nn.Flatten(),\n",
    "    deepcopy(pretrained_model.classifier)\n",
    ")\n",
    "\n",
    "core_net = nn.Sequential(device_side_net,server_side_net,cloud_side_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the exits\n",
    "here the exits are just linear layers, it does not have to be that way, you can define the exits however you want, but the dimensions have to match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exit_layers(neurons_in_layer,number_of_classes=10):\n",
    "    layers = [nn.Flatten()]\n",
    "    for i in range(len(neurons_in_layer)-1):\n",
    "        layers.append(nn.Linear(neurons_in_layer[i],neurons_in_layer[i+1]))\n",
    "        \n",
    "    layers.append(nn.Linear(neurons_in_layer[-1],number_of_classes))\n",
    "    return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16384])\n",
      "torch.Size([16384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# this is the input shape. change it for each use case\n",
    "x = torch.randn(1,3,32,32)\n",
    "\n",
    "\n",
    "\n",
    "exit_0 =device_side_net(x)\n",
    "exit_0_shape = device_side_net(x).flatten().shape\n",
    "print(exit_0_shape)\n",
    "\n",
    "exit_1 = server_side_net(exit_0)\n",
    "exit_1_shape = server_side_net(exit_0).flatten().shape\n",
    "print(exit_1_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_in_exit_0 = [exit_0_shape[0],512,512]\n",
    "neurons_in_exit_1 = [exit_1_shape[0],512,512]\n",
    "\n",
    "exits =nn.ModuleList([get_exit_layers(neurons_in_exit_0),get_exit_layers(neurons_in_exit_1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchvision import  transforms\n",
    "import torch\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='data', train=True,\n",
    "                                       download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the early exit network\n",
    "the class EarlyExitNetwork, pieces together the core network and the exits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "eenet=  EarlyExitNetwork(core_net,exits).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "lr = 1e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "The EarlyExitNetwork class allows the user to either get the results of all the exits, or a specific exti chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output the results for all the extis:\t\t torch.Size([1, 3, 10])\n",
      "Output the results for the exit specified:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1,3,32,32).to(device)\n",
    "print('Output the results for all the extis:\\t\\t',eenet(x).shape)\n",
    "print('Output the results for the exit specified:\\t',eenet(x,exit_chosen=0).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the whole network\n",
    "\n",
    "the test function tests all the exits at the same time (not how the deployed early network works, where only one exit is taken).\n",
    "We can see the correct samples of the first, the second and the third exit, while on the right the number of the total samples.\n",
    "You can infer the acc of each exit by dividing each number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : ([965, 1123, 3975], 10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [00:24<00:00, 63.66it/s, loss=0.594]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Exit 0 :([6420, 8234, 8648], 10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [00:23<00:00, 65.21it/s, loss=0.366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Exit 1 :([6697, 8556, 9042], 10000)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(eenet.parameters(),lr=lr)\n",
    "print(\"Before :\",test_all_exits_accuracy(eenet,testloader))\n",
    "for e in range(2):\n",
    "    train_model(eenet,trainloader,criterion,optimizer) \n",
    "    print(f'Trained Exit {e} :{test_all_exits_accuracy(eenet,testloader)}')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train only one exit\n",
    "when tou want to train only one exit, you first need to specify in the optimizer only the weights of that exit.\n",
    "also you need to pass the exit chosen parameter on the train function, just like we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : ([6697, 8556, 9042], 10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [00:08<00:00, 193.32it/s, loss=0.218] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Exit 1 :([6810, 8556, 9042], 10000)\n"
     ]
    }
   ],
   "source": [
    "exit_taken=0\n",
    "optimizer = torch.optim.Adam(eenet.exits[exit_taken].parameters(),lr=lr)\n",
    "print(\"Before :\",test_all_exits_accuracy(eenet,testloader))\n",
    "train_model(eenet,trainloader,criterion,optimizer,exit_chosen=exit_taken)    \n",
    "print(f'Trained Exit {e} :{test_all_exits_accuracy(eenet,testloader)}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the result on the first exit changed, the other stayed the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : ([6810, 8556, 9042], 10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [00:10<00:00, 144.16it/s, loss=0.0746] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Exit 1 :([6810, 8780, 9042], 10000)\n"
     ]
    }
   ],
   "source": [
    "exit_taken=1\n",
    "optimizer = torch.optim.Adam(eenet.exits[exit_taken].parameters(),lr=lr)\n",
    "\n",
    "print(\"Before :\",test_all_exits_accuracy(eenet,testloader))\n",
    "train_model(eenet,trainloader,criterion,optimizer,exit_chosen=exit_taken)    \n",
    "print(f'Trained Exit {e} :{test_all_exits_accuracy(eenet,testloader)}')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : ([6810, 8780, 9042], 10000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [00:18<00:00, 83.66it/s, loss=0.0882]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Exit 0 :([6810, 8780, 9023], 10000)\n"
     ]
    }
   ],
   "source": [
    "exit_to_train=2\n",
    "optimizer = torch.optim.Adam(eenet.exits[exit_to_train].parameters(), lr=lr)\n",
    "print(\"Before :\",test_all_exits_accuracy(eenet,testloader))\n",
    "for e in range(1):\n",
    "    train_model(eenet,trainloader,criterion,optimizer,exit_chosen=exit_to_train)    \n",
    "    print(f'Trained Exit {e} :{test_all_exits_accuracy(eenet,testloader)}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from early_exit import seperate_networks, SegmentedEarlyExitNetwork,test_networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = seperate_networks(eenet,thresholds=[0.9,0.9]).to(device)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegmentedEarlyExitNetwork(\n",
       "  (network): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (exit): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=16384, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "  (confidence_function): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "networks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8897,\n",
       " {0: {'correct': 3483, 'total': 3802},\n",
       "  1: {'correct': 4360, 'total': 4678},\n",
       "  2: {'correct': 1054, 'total': 1520}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_networks(networks,testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_folder = 'edge_heavy'\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "for i, net in enumerate(networks):\n",
    "    net = net.to('cpu')\n",
    "    model_file = os.path.join(model_folder, f\"model_{i}.pth\")\n",
    "    torch.save(net, model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
